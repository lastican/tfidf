The Mahalanobis distance is a measure of the distance between a point P {\displaystyle P} and a probability distribution D {\displaystyle D}, introduced by P. C. Mahalanobis in 1936.[1] The mathematical details of Mahalanobis distance first appeared in the Journal of The Asiatic Society of Bengal in 1936.[2] Mahalanobis's definition was prompted by the problem of identifying the similarities of skulls based on measurements (the earliest work related to similarities of skulls are from 1922 and another later work is from 1927).[3][4] R.C. Bose later obtained the sampling distribution of Mahalanobis distance, under the assumption of equal dispersion.[5]

It is a multivariate generalization of the square of the standard score z = ( x − μ ) / σ {\displaystyle z=(x-\mu )/\sigma }: how many standard deviations away P {\displaystyle P} is from the mean of D {\displaystyle D}. This distance is zero for P {\displaystyle P} at the mean of D {\displaystyle D} and grows as P {\displaystyle P} moves away from the mean along each principal component axis. If each of these axes is re-scaled to have unit variance, then the Mahalanobis distance corresponds to standard Euclidean distance in the transformed space. The Mahalanobis distance is thus unitless, scale-invariant, and takes into account the correlations of the data set. 